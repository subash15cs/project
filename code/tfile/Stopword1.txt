IEEE
ACM
TRANSACTIONS
NETWORKING
PACK
Prediction
Based
Cloud
Bandwidth
Cost
Reduction
System
Eyal
Zohar
Israel
Cidon
Osnat
Mokryn
Abstract—In
paper
present
PACK
Predictive
ACKs
novel
end
end
traffic
redundancy
elimination
TRE
system
designed
cloud
computing
customers
Cloud
based
TRE
needs
apply
judicious
use
cloud
resources
bandwidth
costreductioncombinedwiththeadditional
cost
TRE
compu
tation
storage
optimized
PACK’s
main
advantage
capability
offloading
cloud
server
TRE
effort
end
clients
thus
minimizing
processing
costs
induced
TRE
algorithm
Unlike
previous
solutions
PACK
require
server
continuously
maintain
clients’
status
makes
PACK
very
suitable
pervasive
computation
environments
com
bine
client
mobility
server
migration
maintain
cloud
elas
ticity
PACK
based
novel
TRE
technique
allows
client
use
newly
received
chunks
identify
previously
received
chunkchains
whichinturncanbeusedasreliablepredictorsto
futuretransmittedchunks
WepresentafullyfunctionalPACKim
plementation
transparent
TCP
based
applications
net
work
devices
Finally
analyze
PACK
benefits
cloud
users
using
traffic
traces
various
sources
IndexTerms—Caching
cloudcomputing
networkoptimization
traffic
redundancy
elimination
INTRODUCTION
C
LOUD
computing
offers
customers
economical
convenient
pay
service
model
known
also
usage
based
pricing
Cloud
customers
pay
only
actual
use
computing
resources
storage
band
width
according
changing
needs
utilizing
cloud’s
scalable
elastic
computational
capabilities
particular
data
transfer
costs
bandwidth
important
issue
trying
minimize
costs
Consequently
cloud
customers
applying
judicious
use
cloud’s
resources
motivated
use
various
traffic
reduction
techniques
particular
traffic
redundancy
elimination
TRE
reducing
bandwidth
costs
Manuscript
received
May
revised
December
accepted
January
approved
IEEE
ACM
TRANSACTIONS
NETWORKING
Editor
L
Li
Zohar
Cidon
Department
Electrical
Engineering
Technion—Israel
Institute
Technology
Haifa
Israel
mail
eyalzo
tx
technion
ac
il
cidon
ee
technion
ac
il
O
Mokryn
Computer
Science
Department
Tel
Aviv
College
Tel
Aviv
Israel
mail
ossi
mta
ac
il
Color
versions
one
more
figures
paper
available
online
http
ieeexplore
ieee
org
Digital
Object
Identifier
TNET
refer
cloud
customers
organizations
export
services
cloud
users
end
users
devices
consume
services
Traffic
redundancy
stems
common
end
users’
activi
ties
suchasrepeatedlyaccessing
downloading
uploading
backup
distributing
modifying
same
similar
infor
mation
items
documents
data
Web
video
TRE
used
eliminate
transmission
redundant
content
fore
significantly
reduce
network
cost
most
common
TRE
solutions
both
sender
receiver
examine
compare
signatures
ofdata
chunks
parsedaccording
data
content
prior
transmission
redundant
chunks
detected
thesenderreplacesthetransmissionofeachredundant
chunk
strong
signature
–
Commercial
TRE
solu
tionsarepopularatenterprisenetworks
andinvolvethedeploy
ment
two
more
proprietary
protocol
state
synchronized
middle
boxes
both
intranet
entry
points
data
centers
branch
offices
eliminating
repetitive
traffic
between
g
Cisco
Riverbed
Quantum
Juniper
Blue
Coat
Expand
Networks
F
proprietary
middle
boxes
popular
point
solutions
within
enterprises
attractive
cloud
environ
ment
Cloud
providers
cannot
benefit
technology
whose
goal
reduce
customer
bandwidth
bills
thus
likely
invest
one
rise
“on
demand”
work
spaces
meeting
rooms
work
home
solutions
detaches
workers
theiroffices
such
dynamic
work
envi
ronment
fixed
point
solutions
require
client
side
server
side
middle
box
pair
become
ineffective
hand
cloud
side
elasticity
motivates
work
distribution
among
servers
migration
among
data
centers
Therefore
com
monly
agreed
universal
software
based
end
end
TRE
crucial
today’s
pervasive
environment
en
ables
use
standard
protocol
stack
makes
TRE
within
end
end
secured
traffic
g
SSL
possible
Current
end
end
TRE
solutions
sender
based
casewherethecloudserveristhesender
thesesolutionsrequire
server
continuously
maintain
clients’
status
show
here
cloud
elasticity
calls
new
TRE
solu
tion
First
cloud
load
balancing
power
optimizations
may
lead
aserver
sideprocessanddatamigrationenvironment
TRE
solutions
require
full
synchronization
between
server
client
hard
accomplish
may
lose
ef
ficiency
due
lost
synchronization
Second
popularity
rich
media
consume
high
bandwidth
motivates
content
dis
tribution
network
CDN
solutions
service
point
fixed
mobile
users
may
change
dynamically
according
relative
service
point
locations
loads
Moreover
end
end
solution
employed
additional
computational
storage
costs
atthe
cloud
side
should
weighed
against
bandwidth
saving
gains
©
IEEE
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
Clearly
aTREsolutionthatputsmostofitscomputationalef
fortonthecloudside
mayturntobelesscost
effectivethanthe
one
leverages
combined
client
side
capabilities
Given
end
end
solution
found
through
our
experiments
thatsender
based
end
end
TRE
solutions
add
con
siderable
load
servers
may
eradicate
cloud
cost
saving
addressed
TRE
first
place
Our
experi
ments
further
show
current
end
end
solutions
also
suffer
requirement
maintain
end
end
synchronization
may
result
degraded
TRE
efficiency
paper
present
novel
receiver
based
end
end
TREsolutionthatreliesonthepowerofpredictionstoeliminate
redundanttrafficbetweenthe
cloudanditsend
users
Inthisso
lution
each
receiver
observes
incoming
stream
tries
match
chunks
previously
received
chunk
chain
chunk
chain
local
file
Using
long
term
chunks’
meta
data
information
kept
locally
receiver
sends
server
predictions
include
chunks’
signatures
easy
verify
hints
sender’s
future
data
sender
first
examines
hint
performs
TRE
operation
only
hint
match
purpose
procedure
avoid
expensive
TRE
com
putation
sender
side
absence
traffic
redundancy
redundancy
detected
sender
then
sends
re
ceiver
only
ACKs
predictions
instead
sending
data
receiver
side
propose
new
computationally
lightweight
chunking
fingerprinting
scheme
termed
PACK
chunking
PACK
chunking
new
alternative
Rabin
fin
gerprinting
traditionally
used
RE
applications
Experiments
show
our
approach
reach
data
processing
speeds
over
Gb
least
faster
than
Rabin
fingerprinting
Offloading
computational
effort
cloud
large
group
clients
forms
load
distribution
action
each
client
processes
only
TRE
part
receiver
based
TRE
solution
addresses
mobility
problems
common
quasi
mobile
desktop
laptopscomputationalenvironments
Oneofthem
iscloudelas
ticityduetowhichtheserversaredynamicallyrelocatedaround
federated
cloud
thus
causing
clients
interact
mul
tiple
changing
servers
Another
property
IP
dynamics
compel
roaming
users
frequently
change
IP
addresses
ad
dition
receiver
based
operation
also
suggest
hy
brid
approach
allows
battery
powered
mobile
device
toshifttheTREcomputationoverheadbacktothecloudbytrig
gering
sender
based
end
end
TRE
similar
validate
receiver
based
TRE
concept
imple
mented
tested
performed
realistic
experiments
PACK
within
cloud
environment
Our
experiments
demon
strate
cloud
cost
reduction
achieved
reasonable
client
effort
gaining
additional
bandwidth
savings
client
side
implementation
code
over
lines
C
Java
obtained
Our
implementation
utilizes
TCP
Options
field
supporting
TCP
based
applications
such
Web
video
streaming
P
P
mail
etc
addition
evaluate
our
solution
compare
pre
vious
end
end
solutions
using
terabytes
real
video
traffic
generally
assume
cloud
side
following
current
Web
service
model
dominated
sender
operation
cases
where
cloud
receiver
referenced
specifically
consumedby
distinctclients
capturedwithinanISP
trafficobtainedinasocialnetworkserviceforoveramonth
demonstrate
our
solution
achieves
redundancy
elimi
nation
without
significantly
affecting
computational
effort
sender
resulting
reduction
overall
cost
cloud
customer
Thispaperisorganizedasfollows
SectionIIreviewsexisting
TRE
solutions
Section
III
present
our
receiver
based
TRE
solution
explain
prediction
process
pre
diction
based
TRE
mechanism
Section
IV
present
opti
mizations
receiver
side
algorithms
Section
evaluates
dataredundancyinacloudandcomparesPACKtosender
based
TRE
Section
VI
details
our
implementation
discusses
our
experiments
results
II
RELATED
WORK
Several
TRE
techniques
explored
recent
years
protocol
independent
TRE
proposed
paper
describesapacket
levelTRE
utilizingthealgorithmspresented
Several
commercial
TRE
solutions
described
havecombinedthesender
basedTREideasof
withthealgo
rithmicandimplementationapproachof
alongwithprotocol
specific
optimizations
middle
boxes
solutions
particular
describes
get
away
three
way
handshake
tween
sender
receiver
full
state
synchronization
maintained
References
present
redundancy
aware
routing
algorithm
papers
assume
routers
equipped
data
caches
search
those
routes
make
better
use
cached
data
Alarge
scalestudyofreal
lifetrafficredundancyispresented
Inthelatter
packet
levelTREtechniques
arecompared
Ourpaperbuildsontheirfindingthat“an
end
end
redundancy
elimination
solution
obtain
most
middle
box’s
bandwidth
savings
”
motivating
benefit
low
cost
software
end
end
solutions
Wanax
TRE
system
developing
world
where
storage
WAN
bandwidth
scarce
software
based
middle
box
replacement
expensive
commercial
hard
ware
Inthisscheme
thesendermiddle
boxholdsbacktheTCP
stream
sends
data
signatures
receiver
middle
box
receiver
checks
whether
data
found
local
cache
Data
chunks
found
cache
fetchedfrom
sender
middle
box
nearby
receiver
middle
box
Naturally
such
scheme
incurs
three
way
handshake
latency
non
cached
data
EndRE
sender
based
end
end
TRE
enterprise
networks
uses
new
chunking
scheme
faster
than
commonlyusedRabinfingerprint
restricted
chunks
small
–
Unlike
PACK
EndRE
requires
server
maintainafullyandreliablysynchronizedcacheforeachclient
adhere
server’s
memory
requirements
caches
arekeptsmall
around
MBperclient
makingthesystemin
adequateformedium
largecontentorlong
termredundancy
EndREis
server
specific
hence
notsuitableforaCDN
orcloud
environment
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Fig
stream
chain
best
our
knowledge
none
previous
works
addressed
requirements
cloud
com
puting
friendly
end
end
TRE
forms
PACK’s
focus
III
PACK
ALGORITHM
sake
clarity
first
describe
basic
receiver
driven
operation
PACK
protocol
Several
enhancements
optimizations
introduced
Section
IV
stream
data
received
PACK
receiver
parsed
sequence
variable
size
content
based
signed
chunks
sim
ilar
chunks
then
compared
receiver
local
storage
termed
chunk
store
matching
chunk
found
local
chunk
store
receiver
retrieves
sequence
subsequent
chunks
referred
chain
traversing
sequence
LRU
chunk
pointers
included
chunks’
metadata
Using
constructed
chain
receiver
sends
prediction
sender
subsequent
data
Part
each
chunk’s
prediction
termed
hint
easy
compute
function
small
enough
false
positive
value
such
value
last
byte
predicted
data
byte
wide
XOR
checksum
selected
bytes
prediction
sent
receiver
includes
range
predicted
data
hint
signature
chunk
sender
identifies
predicted
range
buffered
data
verifies
hint
range
result
matches
received
hint
continues
perform
more
computationally
intensive
SHA
signature
operation
Upon
signature
match
sender
sends
confirmation
mes
sage
receiver
enabling
copy
matched
data
local
storage
Receiver
Chunk
Store
PACK
uses
new
chains
scheme
described
Fig
chunks
linked
chunks
according
last
received
order
PACK
receiver
maintains
chunk
store
large
size
cache
chunks
associated
metadata
Chunk’s
metadata
includes
chunk’s
signature
single
pointer
successive
chunk
last
received
stream
containing
chunk
Caching
indexing
techniques
employed
efficiently
maintain
retrieve
stored
chunks
signatures
chains
formed
traversing
chunk
pointers
new
data
received
parsed
chunks
receiver
computes
each
chunk’s
signature
using
SHA
point
chunk
signature
added
chunk
store
Inaddition
themetadataofthepreviouslyreceivedchunkinthe
same
stream
updated
point
current
chunk
unsynchronized
nature
PACK
allows
receiver
map
each
existing
file
local
file
system
chain
chunks
saving
chunk
store
only
metadata
associated
chunks
Using
latter
observation
receiver
also
share
chunks
peer
clients
within
same
local
net
work
utilizing
simple
map
network
drives
utilization
small
chunk
size
presents
better
redun
dancy
elimination
data
modifications
fine
grained
such
sporadic
changes
HTML
page
hand
use
smaller
chunks
increases
storage
index
size
memory
usage
magnetic
disk
seeks
also
increases
transmission
overhead
virtual
data
exchanged
between
client
server
Unlike
IP
level
TRE
solutions
limited
IP
packet
size
PACK
operates
TCP
streams
therefore
handle
large
chunks
entire
chains
Although
our
design
permits
each
PACK
client
use
any
chunk
size
recommend
average
chunk
size
kB
see
Section
VI
Receiver
Algorithm
Upon
arrival
new
data
receiver
computes
re
spective
signature
each
chunk
looks
match
local
chunk
store
chunk’s
signature
found
receiver
determines
whether
part
formerly
received
chain
using
chunks’
metadata
affirmative
receiver
sends
prediction
sender
several
next
expected
chain
chunks
prediction
carries
starting
point
byte
stream
offset
identity
several
subsequent
chunks
PRED
command
Upon
successful
prediction
sender
responds
PRED
ACK
confirmation
message
Once
PRED
ACK
message
received
processed
receiver
copies
cor
responding
data
chunk
store
TCP
input
buffers
placing
according
corresponding
sequence
numbers
point
receiver
sends
normal
TCP
ACK
next
expected
TCP
sequence
number
case
prediction
false
one
more
predicted
chunks
already
sent
sender
continues
normal
operation
g
sending
raw
data
without
sending
PRED
ACK
message
Proc
Receiver
Segment
Processing
segment
carries
payload
data
then
calculate
chunk
reached
chunk
boundary
then
activate
predAttempt
end
else
PRED
ACK
segment
then
processPredAck
activate
predAttempt
end
De
duplicatedstorage
systemsprovidesimilarfunctionalityandcanbe
used
purpose
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
Proc
predAttempt
received
chunk
matches
one
chunk
store
then
foundChain
chunk
then
prepare
PREDs
send
single
TCP
ACK
PREDs
according
Options
free
space
exit
end
else
store
chunk
link
chunk
current
chain
end
send
TCP
ACK
only
Proc
processPredAck
offset
PRED
ACK
do
read
data
chunk
store
data
TCP
input
buffer
end
C
Sender
Algorithm
WhenasenderreceivesaPREDmessagefromthereceiver
tries
match
received
predictions
buffered
yet
sent
data
each
prediction
sender
determines
corre
sponding
TCP
sequence
range
verifies
hint
Upon
hint
match
thesendercalculatesthemorecomputationallyintensive
SHA
signature
predicted
data
range
compares
result
signature
received
PRED
message
Note
incasethehintdoesnotmatch
acomputationallyexpansiveop
eration
saved
two
SHA
signatures
match
sender
cansafelyassumethatthereceiver’spredictioniscorrect
Inthis
case
replaces
corresponding
outgoing
buffered
data
PRED
ACK
message
Fig
illustrates
sender
operation
using
state
machines
Fig
describes
parsing
received
PRED
command
Fig
describeshowthesenderattemptstomatchapredicted
range
outgoing
data
First
finds
range
already
sent
case
range
already
ac
knowledged
corresponding
prediction
discarded
wise
tries
match
prediction
data
outgoing
TCP
buffers
D
Wire
Protocol
order
conform
existing
firewalls
minimize
overheads
use
TCP
Options
field
carry
PACK
wire
protocol
clear
PACK
also
implemented
above
TCP
level
using
similar
message
types
control
fields
Fig
illustrates
way
PACK
wire
protocol
operates
undertheassumptionthatthedataisredundant
First
bothsides
enable
PACK
option
during
initial
TCP
handshake
Fig
Sender
algorithms
Filling
prediction
queue
Processing
prediction
queue
sending
PRED
ACK
raw
data
adding
PACK
permitted
flag
denoted
bold
line
TCP
Options
field
Then
sender
sends
redundant
data
one
more
TCP
segments
receiver
identifies
currently
received
chunk
identical
chunk
chunk
store
receiver
turn
triggers
TCP
ACK
message
includes
prediction
packet’s
Options
field
Last
sender
sends
confirmation
message
PRED
ACK
replacing
actual
data
IV
OPTIMIZATIONS
sake
clarity
Section
III
presents
most
basic
version
PACK
protocol
section
describe
ad
ditional
options
optimizations
Adaptive
Receiver
Virtual
Window
PACK
enables
receiver
locally
obtain
sender’s
data
whenalocalcopyisavailable
thuseliminatingtheneedtosend
data
through
network
term
receiver’s
fetching
such
local
data
reception
virtual
data
sender
transmits
high
volume
virtual
data
connection
rate
may
certain
extent
limited
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Fig
PACK
wire
protocol
nutshell
number
predictions
sent
receiver
turn
means
thatthereceiverpredictionsandthesenderconfirmationsshould
expedited
order
reach
high
virtual
data
rate
ex
ample
case
repetitive
success
predictions
re
ceiver’s
side
algorithm
may
become
optimistic
gradually
increase
ranges
predictions
similarly
TCP
rate
adjustment
procedures
PACK
enables
large
prediction
size
either
sending
sev
eral
successive
PRED
commands
enlarging
PRED
com
mand
range
cover
several
chunks
PACK
enables
receiver
combine
several
chunks
into
single
range
sender
bounded
anchors
origi
nally
used
receiver’s
data
chunking
algorithm
com
binedrangehasanewhintandanewsignaturethatisanSHA
concatenated
content
chunks
variable
prediction
size
introduces
notion
vir
tual
window
current
receiver’s
window
virtual
data
virtual
window
receiver’s
upper
bound
aggregated
number
bytes
pending
predictions
virtual
window
first
set
minimal
value
identical
receiver’s
flow
control
window
receiver
increases
virtual
window
each
prediction
success
according
following
description
Upon
first
chunk
match
receiver
sends
predictions
limited
initial
virtual
window
likely
before
predictions
arrive
sender
some
corresponding
real
data
already
transmitted
real
data
arrives
receiver
partially
confirm
prediction
increase
virtual
window
Upon
getting
PRED
ACK
confirmations
sender
receiver
also
increases
virtual
window
logic
resembles
slow
start
part
TCP
rate
control
algo
rithm
mismatch
occurs
receiver
switches
back
initial
virtual
window
Proc
describes
advanced
algorithm
performed
receiver’s
side
code
lines
–
describes
PACK
behavior
whenadatasegmentarrivesafteritspredictionwassentandthe
virtual
window
doubled
Proc
describes
reception
successful
acknowledgement
message
PRED
ACK
sender
receiver
reads
data
local
chunk
store
Itthenmodifiesthenextbytesequencenumbertothelastbyteof
theredundantdatathathasjustbeenreadplusone
andsendsthe
next
TCP
ACK
piggybacked
new
prediction
Finally
virtual
window
doubled
Proc
predAttemptAdaptive
—obsoletes
Proc
new
code
Adaptive
received
chunk
overlaps
recently
sent
prediction
then
received
chunk
matches
prediction
then
predSizeExponent
else
predSizeReset
end
end
received
chunk
matches
one
signature
cache
then
foundChain
chunk
then
new
code
Adaptive
prepare
PREDs
according
predSize
send
TCP
ACKs
PREDs
exit
end
else
store
chunk
append
chunk
current
chain
end
send
TCP
ACK
only
Proc
processPredAckAdaptive
—obsoletes
Proc
offset
PRED
ACK
do
read
data
disk
data
TCP
input
buffer
end
new
code
Adaptive
predSizeExponent
size
increase
virtual
window
introduces
tradeoff
case
prediction
fails
some
point
code
Proc
line
describes
receiver’s
behavior
riving
data
match
recently
sent
predictions
new
received
chunk
may
course
start
new
chain
match
Following
reception
data
receiver
reverts
initial
virtual
window
conforming
normal
TCP
receiver
windowsize
untilanewmatchisfoundinthechunkstore
Note
even
slight
change
sender’s
data
compared
saved
chain
causes
entire
prediction
range
sent
receiver
raw
data
Hence
using
large
virtual
windows
intro
ducesatradeoffbetweenthepotentialrategainandtherecovery
effort
case
missed
prediction
Cloud
Server
Receiver
growing
trend
cloud
storage
becoming
dominant
player
—from
backup
sharing
services
American
National
Library
mail
services
many
services
cloud
often
receiver
data
sending
client
no
power
limitations
PACK
work
save
bandwidth
upstream
cloud
cases
end
user
acts
sender
cloud
server
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
receiver
PACK
algorithm
need
change
require
cloud
server—like
any
PACK
re
ceiver—maintain
chunk
store
C
Hybrid
Approach
PACK’sreceiver
basedmodeislessefficientifchangesinthe
data
scattered
case
prediction
sequences
fre
quently
interrupted
turn
forces
sender
revert
raw
data
transmission
until
new
match
found
re
ceiver
reported
back
sender
end
present
PACK
hybrid
mode
operation
described
Proc
Proc
WhenPACKrecognizesapatternofdispersedchanges
may
select
trigger
sender
driven
approach
spirit
Proc
Receiver
Segment
Processing
Hybrid—obsoletes
Proc
segment
carries
payload
data
then
calculate
chunk
reached
chunk
boundary
then
activate
predAttempt
new
code
Hybrid
detected
broken
chain
then
calcDispersion
else
calcDispersion
end
end
else
PRED
ACK
segment
then
processPredAck
activate
predAttempt
end
Proc
processPredAckHybrid
—obsoletes
Proc
offset
PRED
ACK
do
read
data
disk
data
TCP
input
buffer
new
code
Hybrid
chunk
offset
do
calcDispersion
end
end
explained
earlier
revert
sender
driven
mode
minimal
computational
buffering
overhead
server
steady
state
Therefore
our
approach
first
evaluate
receiver
need
sender
driven
operation
then
report
back
sender
point
sender
decide
enough
resources
process
sender
driven
TRE
some
clients
support
enhancement
additional
command
DISPER
intro
duced
Using
command
receiver
periodically
sends
estimated
level
dispersion
ranging
long
smooth
chains
up
TABLE
DATA
PACK’S
RESULTS
hYOUTUBE
TRAFFIC
TRACE
PACK
computes
data
dispersion
value
using
exponen
tial
smoothing
function
where
smoothing
factor
value
set
chain
break
detected
otherwise
MOTIVATING
RECEIVER
BASED
APPROACH
objective
section
twofold
evaluating
po
tential
data
redundancy
several
applications
likely
reside
cloud
estimate
PACK
performance
cloud
costs
redundancy
elimination
process
Ourevaluationsareconductedusing
videotracescaptured
atamajorISP
trafficobtained
popularsocialnetwork
service
genuine
data
sets
real
life
workloads
section
relate
average
chunk
size
kB
although
our
algorithm
allows
each
client
use
different
chunk
size
Traffic
Redundancy
Traffic
Traces
obtained
h
recording
trafficat
ISP’s
Gb
PoP
router
using
GHz
CPU
recording
machine
TB
storage
GB
RPM
disks
Gb
NIC
filtered
YouTube
traffic
using
deep
packet
inspectionandmirroredtrafficassociatedwithYouTubeservers
IP
addresses
our
recording
device
Our
measurements
show
YouTube
traffic
accounts
total
daily
Web
traffic
volume
ISP
recording
full
YouTube
stream
require
times
our
network
disk
write
speeds
Therefore
isolated
obtained
YouTube
traffic
grouped
video
identifier
keeping
redundancy
level
intact
using
programmed
load
balancer
examined
upstream
HTTP
requests
redirected
downstream
ses
sions
according
video
identifier
found
YouTube’s
URLs
total
TB
accurate
reading
thetrueredundancy
wefiltered
client
IP
addresses
were
used
too
intensively
represent
single
user
were
assumed
represent
NAT
address
Note
YouTube’s
video
content
cacheable
stan
dard
Web
proxies
since
URL
contains
private
single
use
kens
changed
each
HTTP
request
Moreover
most
Web
browsers
cannot
cache
reuse
partial
movie
downloads
occur
end
users
skip
within
movie
switch
another
movie
before
previous
one
ends
Table
summarizes
our
findings
recorded
more
than
K
distinct
sessions
K
users
request
over
K
distinct
movies
Average
movie
size
MB
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Fig
ISP’s
YouTube
traffic
over
h
PACK
redundancy
elimination
ratio
data
average
session
size
MB
difference
stemming
end
user
skips
interrupts
data
sliced
into
kB
chunks
PACK
brings
traffic
savings
up
assuming
end
users
start
empty
cache
worst
case
scenario
Fig
presents
YouTube
traffic
redundancy
ob
tained
PACK
over
entire
period
redundancy
sampled
every
min
averaged
end
end
redun
dancy
arises
solely
self
similarity
traffic
created
end
users
further
analyzed
cases
found
end
users
very
often
download
same
movie
parts
repeatedly
latter
mainly
intersession
redundancy
pro
duced
end
users
skip
forward
backward
movie
producing
several
partially
overlapping
downloads
Such
skipsoccurredat
ofthesessionsandmostlyinlongmovies
over
MB
Since
assume
cache
empty
beginning
takes
chunk
cache
fill
up
enter
steady
state
steady
state
around
traffic
identified
redun
dant
removed
explain
length
warm
up
time
fact
YouTube
allows
browsers
cache
movies
h
results
some
replays
do
produce
down
loads
Static
Dataset
acquired
following
static
datasets
Linux
source—different
Linux
kernel
versions
xtarfilesofthekernelsourcecodethatsumupto
GB
Email—asingle
userGmailaccountwith
mailmes
sagesoverayearthatsumupto
GB
Linux
source
versions
were
released
over
period
years
tar
files
original
release
order
were
downloaded
download
directory
mapped
PACK
measure
amount
redundancy
resulted
traffic
Fig
shows
redundancy
each
down
loaded
versions
Altogether
Linux
source
files
show
redundancy
accounts
MB
obtain
estimate
redundancy
mail
traffic
operated
IMAP
client
fully
synchronized
remote
Gmail
account
new
local
folder
Fig
shows
redundancy
each
month
according
mail
message’s
Fig
Traffic
volume
detected
redundancy
Linux
source
different
Linux
kernel
versions
Email
year
Gmail
account
month
issue
date
total
measured
traffic
redundancy
roughly
MB
found
redundancy
arise
large
attachments
sent
multiple
sources
mail
correspondence
similar
documents
development
process
replies
large
quoted
text
result
conservative
estimate
amount
redun
dancyin
cloude
mailtraffic
because
inpractice
some
messages
read
downloaded
multiple
times
example
Gmail
user
reads
same
attachment
times
directly
Web
browser
generates
redundant
traffic
Our
experiments
show
order
derive
efficient
PACK
redundancy
elimination
chunk
level
redundancy
needs
applied
along
long
chains
quantify
phe
nomenon
explored
distribution
redundant
chains
Linux
Email
datasets
Fig
presents
resulted
redundant
data
chain
length
distribution
Linux
chunks
found
chains
Email
about
Moreover
redundant
chunks
more
probable
reside
long
chains
findings
sustain
our
conclusion
once
redundancy
discovered
single
chunk
likely
continue
subsequent
chunks
Furthermore
our
evaluations
show
videos
large
files
small
amount
changes
redundant
chunks
likely
reside
very
long
chains
efficiently
handled
receiver
based
TRE
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
TABLE
II
SENDER
COMPUTATIONAL
EFFORT
COMPARISON
BETWEEN
DIFFERENT
TRE
MECHANISMS
Fig
Chain
length
histogram
Linux
Software
Email
data
collections
Receiver
Based
Versus
Sender
Based
TRE
section
evaluate
sender
performance
PACK
well
sender
based
end
end
TRE
Server
Computational
Effort
First
evaluate
com
putationaleffortofthe
serverin
bothcases
PACK
theserver
required
perform
SHA
operation
over
defined
range
bytes
prediction
determines
starting
point
offset
size
prediction
only
verifies
hint
sent
part
prediction
matches
data
sender
based
TRE
server
required
first
compute
Rabin
fingerprints
order
slice
stream
into
chunks
then
computeanSHA
signatureforeachchunk
priortosendingit
Table
II
presents
summary
server
computational
effort
each
sender
based
TRE
described
literature
well
PACK
Tofurtherevaluatetheservercomputationaleffortforthedif
ferent
sender
based
PACK
TRE
schemes
measured
servereffortasafunctionoftimeandtrafficredundancy
Forthe
sender
based
scheme
simulated
approach
using
published
performance
benchmarks
then
measured
server
performance
function
download
time
redundant
traffic
Email
dataset
contains
taken
benchmarks
kB
chunks
SHA
calculation
throughput
about
Mb
Pentium
III
MHz
Mb
Pentium
D
GHz
Rabin
fingerprint
chunking
reported
–
times
slower
redundancy
sender
effort
expressed
number
SHA
operations
per
second
Fig
demonstrates
high
effort
placed
server
sender
based
scheme
compared
much
lower
effort
PACK
sender
performs
SHA
operations
only
data
matches
hint
Moreover
Fig
shows
PACK
server
computational
effort
grows
linearly
amount
redundant
data
result
server
works
only
re
dundancy
observed
clientreads
data
local
storage
instead
receiving
server
scenario
demonstrates
server’s
client’s
incentives
meet
Whiletheserverinveststheeffortintosavingtrafficvolume
client
cooperates
save
volume
get
faster
downloads
Synchronization
Several
sender
based
end
end
TRE
mechanisms
require
full
synchronization
between
sender
receiver
caches
such
synchronization
exists
redundancy
detected
eliminated
up
front
sender
synchronization
saves
otherwise
required
three
way
handshake
ignores
redundant
chunks
arrive
receiver
different
senders
problem
avoided
PACK
did
account
extra
efficiency
our
current
study
further
understand
TRE
work
cloud
based
Web
service
returning
end
users
ob
tained
traffic
log
social
network
site
period
days
end
data
log
enables
reliable
long
term
detection
returning
users
users
identify
selves
using
login
enter
site
identified
sessions
registered
users
over
period
then
measured
amount
TRE
obtained
different
cache
sizes
receiver
synchronized
sender
based
TRE
keeps
mirror
last
period
cache
size
Fig
showstheredundancythatcanbeobtainedfordifferent
caching
periods
Clearly
short
term
cache
cannot
identify
re
turning
long
term
sessions
Users
Mobility
Using
social
network
dataset
pre
sented
above
explored
effectofusers’
mobility
TRE
Clearly
PACK
directed
mobile
devices
users
who
use
stations
different
locations
experiment
focused
users
connected
through
G
cel
lularnetworkswithmanydevicetypes
PCs
smartphones
etc
Users
required
complete
registration
progress
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Fig
Difference
computation
efforts
between
receiver
sender
driven
modes
transmission
Email
data
collection
Server
effort
func
tion
oftime
Sender
effortrelativeto
redundantchunkssignaturesdownload
time
virtual
speed
Fig
Social
network
site
traffic
redundancy
per
day
different
time
lengths
cache
enter
unique
cellular
phone
number
get
pass
word
through
SMS
message
Fig
Number
cloud
servers
needed
serving
YouTube
traffic
without
TRE
sender
based
TRE
PACK
found
cellular
sessions
were
conducted
users
also
got
connected
site
through
noncel
lular
ISP
same
device
Clearly
TRE
solutions
attached
specific
location
rely
static
client
IP
address
cannot
exploit
redundancy
Another
related
finding
cellular
ses
sions
used
IP
addresses
were
previously
used
others
same
dataset
noncellular
sessions
found
only
IP
reuse
one
also
major
obstacle
synchronized
solutions
require
reliable
protocol
independent
detection
returning
clients
C
Estimated
Cloud
Cost
YouTube
Traffic
Traces
Asnotedbefore
althoughTREreducescloudtrafficcosts
increasedservereffortsforTREcomputationresultinincreased
server
hours
cost
evaluate
here
cloud
cost
serving
YouTube
videos
described
Section
compare
three
setups
without
TRE
PACK
sender
based
TRE
cost
comparison
takes
into
account
server
hours
overall
outgoing
traffic
throughput
omitting
storage
costs
found
very
similar
examined
setups
baseline
comparison
our
measurement
single
video
server
outputs
up
Mb
concur
rent
clients
Given
cloud
array
such
servers
set
cloud
policy
add
server
less
than
CPU
computation
power
unemployed
array
server
removed
array
removal
least
CPU
power
left
unused
sender
based
TRE
evaluated
only
using
server’s
cost
SHA
operation
per
every
outgoing
byte
performed
previously
published
works
detect
YouTube’s
long
term
redundancy
Fig
shows
shaded
part
number
server
hours
used
serve
YouTube
traffic
cloud
no
TRE
mechanism
our
base
figure
costs
taken
cost
figure
comparison
Fig
also
shows
number
server
hours
needed
forthistaskwitheitherPACK
TRE
sender
based
TRE
PACK
puts
extra
load
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
Fig
Overview
PACK
implementation
TABLE
III
CLOUD
OPERATIONAL
COST
COMPARISON
almost
one
server
only
time
accounts
fortheamountofredundancyeliminated
thesender
basedTRE
scheme
requires
between
one
two
additional
servers
al
most
time
resulting
higher
operational
cost
redundancy
elimination
Table
III
summarizes
costs
benefits
TRE
operations
compares
baseline
no
TRE
total
operational
cost
based
current
Amazon
EC
pricing
given
traffic
intensive
scenario
traffic
server
hours
cost
ratio
Both
TRE
schemes
identify
elimi
nate
traffic
redundancy
PACK
employs
server
only
redundancy
exists
sender
based
TRE
em
ploys
entire
period
time
consuming
more
servers
than
PACK
no
TRE
schemes
no
little
redundancy
detected
VI
IMPLEMENTATION
section
present
PACK
implementation
perfor
mance
analysis
projected
server
costs
derived
implementation
experiments
Our
implementation
contains
over
lines
C
Java
code
runs
Linux
Netfilter
Queue
Fig
shows
PACK
implementation
architecture
server
side
use
Intel
Core
Duo
GHz
GB
RAM
WD
AAJS
SATA
drive
desktop
clients
laptop
machines
based
Intel
Core
Duo
GHz
GB
RAM
WD
BJKT
SATA
drive
OurimplementationenablesthetransparentuseoftheTREat
boththeserverandtheclient
PACKreceiver–senderprotocolis
embedded
TCP
Options
field
low
overhead
com
patibility
legacy
systems
along
path
keep
gen
uine
operating
systems’
TCP
stacks
intact
allowing
seamless
integration
applications
protocols
above
TCP
Chunking
indexing
performed
only
client’s
side
enabling
clients
decide
independently
pre
ferred
chunk
size
our
implementation
client
uses
av
erage
chunk
size
kB
found
size
achieve
high
TRE
hit
ratio
evaluated
datasets
adding
only
neg
ligibleoverheadsof
inmetadatastorageand
inpre
dictions
bandwidth
Fortheexperimentsheldinthissection
wegeneratedawork
load
consisting
Section
datasets
IMAP
mails
HTTP
videos
files
downloaded
over
FTP
workload
then
loaded
server
consumed
clients
sampled
machines’
status
every
second
measure
real
virtual
traffic
volumes
CPU
utilization
Server
Operational
Cost
measured
server
performance
cost
function
data
redundancy
level
order
capture
effect
TRE
mechanisms
real
environment
isolate
TRE
oper
ational
cost
measured
server’s
trafficvolumeandCPU
utilization
maximal
throughput
without
operating
TRE
then
used
numbers
reference
cost
based
present
Amazon
EC
pricing
server
operational
cost
com
posed
both
network
trafficvolumeandtheCPUutiliza
tion
derived
EC
pricing
constructed
system
consisting
one
server
seven
clientsovera
Gb
snetwork
Theserverwasconfiguredtopro
vide
maximal
throughput
Mb
per
client
then
mea
sured
three
different
scenarios
baseline
no
TRE
operation
PACK
sender
based
TRE
similar
EndRE’s
Chunk
Match
referredtoasEndRE
FortheEndRE
likecase
accountedfor
SHA
calculatedovertheentireoutgoing
traffic
did
account
chunking
effort
case
EndRE
made
assumption
unlimited
buffers
both
server
client
sidesto
enable
thesame
long
term
re
dundancy
level
TRE
ratio
PACK
Fig
presents
overall
processing
networking
cost
traffic
redundancy
relative
no
TRE
operation
redundancy
grows
PACK
server
cost
decreases
due
bandwidth
saved
unsent
data
EndRE
server
gain
significant
cost
reduction
since
SHA
operations
performed
over
nonredundant
data
well
Note
above
redundancy
common
reviewed
datasets
PACK
operational
cost
least
lower
than
EndRE
PACK
Impact
Client
CPU
evaluate
CPU
effort
imposed
PACK
client
measured
random
client
scenario
similar
one
used
measuring
server’s
cost
only
time
cloud
server
streamed
videos
rate
Mb
each
client
Such
speed
throttling
very
common
real
time
video
servers
aim
provide
clients
stable
bandwidth
smooth
view
Table
IV
summarizes
results
average
PACK
related
CPU
consumption
client
less
than
Mb
video
redundancy
Fig
presents
client
CPU
utilization
function
real
incoming
traffic
bandwidth
Since
client
chunks
arriving
data
CPU
utilization
grows
more
real
traffic
enters
client’s
machine
Fig
shows
client
CPU
utilization
function
virtual
traffic
bandwidth
Vir
tual
traffic
arrives
form
prediction
approvals
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Fig
PACK
versus
EndRE
cloud
server
operational
cost
function
redundancy
ratio
TABLE
IV
CLIENT
CPU
UTILIZATION
STREAMING
Mb
VIDEO
WITHOUT
PACK
sender
limited
rate
Mb
server’s
throt
tling
approvals
save
client
need
chunk
data
sign
chunks
enable
him
send
more
predictions
based
same
chain
just
used
successfully
Hence
more
redundancy
found
less
CPU
utilization
incurred
PACK
C
Chunking
Scheme
Our
implementation
employs
novel
computationally
lightweight
chunking
fingerprinting
scheme
termed
PACK
chunking
scheme
presented
Proc
illustrated
Fig
XOR
based
rolling
hash
function
tailored
fast
TRE
chunking
Anchors
detected
mask
line
provides
average
kB
chunks
mask
shown
Fig
chosen
consider
sliding
window
Proc
PACK
chunking
algorithm
bytes
window
KB
chunks
bits
byte
stream
do
shift
left
longval
bit
dropmsb
bitwise
xor
byte
processed
least
bytes
longval
bitwise
mask
then
found
anchor
end
end
Fig
Client
CPU
utilization
function
received
traffic
client’s
CPU
utilization
without
TRE
used
baseline
Real
traffic
Virtual
traffic
Fig
PACK
chunking
snapshot
least
were
processed
Our
measurements
show
PACK
chunking
faster
than
fastest
knownRabinfingerprint
software
implementa
tion
due
one
less
XOR
operation
per
byte
further
measured
PACK
chunking
speed
compared
schemes
measurements
were
performed
unloaded
CPU
whose
only
operation
chunk
MB
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
IEEE
ACM
TRANSACTIONS
NETWORKING
Fig
Receiver
message
example
large
range
prediction
TABLE
CHUNKING
SCHEMES
PROCESSING
SPEED
TESTED
MB
RANDOM
FILE
OVER
CLIENT’S
LAPTOP
WITHOUT
EITHER
MINIMAL
MAXIMAL
LIMIT
CHUNK
SIZE
random
binary
file
Table
summaries
processing
speed
different
chunking
schemes
baseline
figure
wemea
sured
speed
SHA
signing
found
reached
Mb
D
Pack
Messages
Format
our
implementation
use
two
currently
unused
TCP
op
tion
codes
similar
ones
definedinSACK
Thefirst
one
enabling
option
PACK
permitted
sent
SYN
seg
ment
indicate
PACK
option
used
connection
established
one
PACK
message
may
sent
over
established
connection
once
permis
sion
granted
both
parties
single
PACK
message
piggybacked
single
TCP
packet
designed
wrap
carry
multiple
PACK
commands
illustrated
Fig
only
saves
message
overhead
also
copes
security
networkdevices
g
firewall
thattend
change
TCPoptions
order
NotethatmostTCPoptionsareonlyusedattheTCP
initializationperiod
withseveralexceptionssuchasSACK
timestamps
Due
lack
space
additional
implementation
details
left
available
VII
CONCLUSION
CloudcomputingisexpectedtotriggerhighdemandforTRE
solutions
amount
data
exchanged
between
cloud
users
expected
dramatically
increase
cloud
en
vironmentredefinestheTRE
systemrequirements
makingpro
prietary
middle
box
solutions
inadequate
Consequently
rising
need
TRE
solution
reduces
cloud’s
op
erational
cost
accounting
application
latencies
user
mobility
cloud
elasticity
paper
presented
PACK
receiver
based
cloud
friendly
end
end
TRE
based
novel
specula
tive
principles
reduce
latency
cloud
operational
cost
PACK
require
server
continuously
maintain
clients’
status
thus
enabling
cloud
elasticity
user
mobility
preserving
long
term
redundancy
Moreover
PACK
capable
eliminating
redundancy
based
content
arriving
client
multiple
servers
without
applying
three
way
handshake
Ourevaluationusingawidecollectionofcontenttypesshows
thatPACKmeetstheexpecteddesigngoalsandhasclearadvan
tages
over
sender
based
TRE
especially
cloud
com
putation
cost
buffering
requirements
important
More
over
PACK
imposes
additional
effort
sender
only
redundancy
exploited
thus
reducing
cloud
overall
cost
Twointerestingfutureextensionscanprovideadditionalben
efits
PACK
concept
First
our
implementation
maintains
chains
keeping
any
chunk
only
last
observed
sub
sequent
chunk
LRU
fashion
interesting
extension
work
statistical
study
chains
chunks
enable
multiple
possibilities
both
chunk
order
corresponding
predictions
system
may
also
allow
making
more
than
one
prediction
time
enough
one
will
correct
successful
traffic
elimination
second
promisingdirectionisthemodeofoperationoptimizationofthe
hybrid
sender–receiver
approach
based
shared
decisions
de
rived
receiver’s
power
server’s
cost
changes
REFERENCES
Zohar
Cidon
O
Mokryn
“The
power
prediction
Cloud
bandwidth
cost
reduction
”
Proc
SIGCOMM
pp
–
Armbrust
Fox
R
Griffith
D
Joseph
R
Katz
Konwinski
G
Lee
D
Patterson
Rabkin
Stoica
Zaharia
“A
view
cloud
computing
”
Commun
ACM
vol
no
pp
–
U
Manber
“Finding
similar
files
large
file
system
”
Proc
USENIX
Winter
Tech
Conf
pp
–
N
Spring
D
Wetherall
“A
protocol
independent
technique
eliminatingredundantnetworktraffic
”inProc
SIGCOMM
vol
pp
–
Muthitacharoen
Chen
D
Mazières
“A
low
bandwidth
net
work
file
system
”
Proc
SOSP
pp
–
Lev
Ran
Cidon
andI
Z
Ben
Shaul
“Methodandapparatus
reducing
network
traffic
over
low
bandwidth
links
”
US
Patent
Nov
MccanneandM
Demmer
“Content
basedsegmentationschemefor
data
compression
storage
transmission
including
hierarchical
segment
representation
”
US
Patent
Dec
R
Williams
“Method
partitioning
block
data
into
subblocks
storing
communicating
such
subblocks
”
US
Patent
Nov
Juniper
Networks
Sunnyvale
CA
USA
“Application
accel
eration
”
Online
Available
http
www
juniper
net
us
en
products
services
application
acceleration
Blue
Coat
Systems
Sunnyvale
CA
USA
“MACH
”
Online
Available
http
www
bluecoat
com
products
mach
Expand
Networks
Riverbed
Technology
San
Francisco
CA
USA
“Application
acceleration
WAN
optimization
”
Online
Available
http
www
expand
com
technology
application
acceleration
aspx
F
Seattle
USA
“WANoptimization
”
Online
Available
http
www
f
com
solutions
acceleration
wan
optimization
Flint
“The
next
workplace
revolution
”
Nov
Online
Available
http
theatlanticcities
com
jobs
economy
nextworkplace
revolution
Anand
C
Muthukrishnan
Akella
andR
Ramjee
“Redundancy
network
traffic
Findings
implications
”
Proc
SIGMETRICS
pp
–
article
accepted
inclusion
future
issue
journal
Content
final
presented
exception
pagination
ZOHAR
et
al
PACK
PREDICTION
BASED
CLOUD
BANDWIDTH
COST
REDUCTION
SYSTEM
Aggarwal
Akella
Anand
Balachandran
P
Chitnis
C
Muthukrishnan
R
Ramjee
G
Varghese
“EndRE
end
system
redundancy
elimination
service
enterprises
”
Proc
NSDI
pp
–
“PACK
source
code
”
Online
Available
http
www
eyalzo
com
projects
pack
Anand
Gupta
Akella
Seshan
Shenker
“Packet
cachesonrouters
Theimplicationsofuniversalredundanttrafficelim
ination
”
Proc
SIGCOMM
pp
–
Anand
Sekar
Akella
“SmartRE
architecture
coordinated
network
wide
redundancy
elimination
”
Proc
SIG
COMM
vol
pp
–
Gupta
Akella
Seshan
Shenker
J
Wang
“Under
standing
exploiting
network
traffic
redundancy
”
UW
Madison
Madison
WI
USA
Tech
Rep
Apr
Zink
K
Suh
Y
Gu
J
Kurose
“Watch
global
cache
local
YouTubenetworktrafficatacampusnetwork—Measurementsandim
plications
”
Proc
MMCN
pp
–
Schleimer
D
Wilkerson
Aiken
“Winnowing
Local
al
gorithms
document
fingerprinting
”
Proc
SIGMOD
pp
–
Ihm
K
Park
Pai
“Wide
area
network
acceleration
developing
world
”
Proc
USENIX
ATC
pp
–
H
Stevens
C
Pettey
“Gartner
says
cloud
computing
will
influential
business
”
Gartner
Newsroom
Jun
H
Abu
Libdeh
L
Princehouse
andH
Weatherspoon
“RACS
Acase
cloud
storage
diversity
”
Proc
SOCC
pp
–
“Dropbox
”
Online
Available
http
www
dropbox
com
AllenandC
Morris
“LibraryofCongressandDuracloudlaunch
pilot
program
using
cloud
technologies
test
perpetual
access
dig
ital
content
”
News
Release
Jul
D
Hansen
“GMailfilesystemoverFUSE
”
Online
Available
http
sr
net
projects
gmailfs
J
Srinivasan
Wei
X
Ma
andT
Yu
“EMFS
Email
basedpersonal
cloud
storage
”
Proc
NAS
pp
–
“Amazon
Elastic
Compute
Cloud
EC
”
Online
Available
http
aws
amazon
com
ec
“netfilter
iptables
project
Libnetfilter
queue
”
Oct
Online
Available
http
www
netfilter
org
projects
libnetfilter
queue
Z
Broder
“Some
applications
Rabin’s
fingerprinting
method
”
Sequences
II
Methods
Communications
Security
Computer
Science
New
York
NY
USA
Springer
Verlag
pp
–
Mathis
J
Mahdavi
Floyd
Romanow
“TCP
selective
acknowledgment
options
”
RFC
Medina
Allman
Floyd
“Measuring
evolution
transport
protocols
internet
”
Comput
Commun
Rev
vol
no
pp
–
Jacobson
R
Braden
D
Borman
“TCP
extensions
high
performance
”
RFC
Eyal
Zohar
received
Sc
degrees
computer
science
Open
University
Ra’anana
Israel
respectively
currently
pursuing
Ph
D
degree
electrical
engineering
Technion—Israel
Institute
Technology
Haifa
Israel
vast
experience
network
related
soft
ware
development
several
startup
companies
research
interests
include
P
P
networks
content
caching
cloud
computing
cellular
networks
traffic
redundancy
elimination
Mr
Zohar
recipient
Intel
Award
graduate
students
IsraelCidonreceivedtheB
Sc
andPh
D
degreesin
electrical
engineering
Technion—Israel
stituteofTechnology
Haifa
Israel
respectively
Professor
electrical
engineering
Technion
hewastheDeanofthe
Electrical
Engineering
Faculty
Technion
Between
Manager
Network
Architecture
Algorithms
IBM
J
Watson
Research
Center
Yorktown
Heights
NY
leading
several
computer
networks
projects
including
first
implementations
packet
based
multimedia
network
IBM
first
storage
area
network
During
founded
managed
high
speed
networking
group
Sun
Microsystems
Labs
Mountain
View
CA
cofounded
Micronet
Ltd
Tel
Aviv
Israel
early
vendor
mobile
data
entry
terminals
cofounded
Viola
Net
works
Yokneam
Israel
provider
network
VoIP
performance
diagnostic
suite
acquired
Fluke
Networks
cofounded
Actona
Technologies
Haifa
Israel
acquired
Cisco
pioneered
technology
wide
area
file
systems
WAFS
technology
adopted
most
large
enterprises
cofounded
Sookasa
Mountain
View
CA
USA
provider
unstructured
data
security
management
storage
cloud
services
coauthor
over
refereed
papers
US
patents
current
research
involves
wire
line
wireless
communication
networks
chip
interconnects
networks
Dr
Cidon
received
IBM
Outstanding
Innovation
Award
twice
Osnat
Ossi
Mokryn
received
Sc
degree
computerscienceandM
Sc
degreeinelectricalengi
neering
Technion—Israel
Institute
Tech
nology
Haifa
Israel
respectively
Ph
D
degree
computer
science
Hebrew
University
Jerusalem
Israel
extensive
high
tech
experience
leading
companies
such
Intel
IBM
research
labs
Haifa
Israel
Post
Doctorate
Fellow
Electrical
Engineering
Department
Tel
Aviv
University
Tel
Aviv
Israel
Starting
faculty
heading
Internet
Computer
Networks
field
School
Computer
Science
Tel
Aviv
Jaffa
Academic
College
Tel
Aviv
Israel
Her
recent
research
focuses
content
aware
caching
wireless
opportunistic
networks
data
mining
recommender
systems
